{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Classifiers for Dataset 3:\n",
    "### a. GMM based classifier with 8 Gaussians per class and using (i) Full covariance matrices and (ii) Diagonal covariance matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task\n",
    "1. Datasets 3: Confusion matrices and classification accuracies for the training data and the \n",
    "test data, and for each of the classifiers.\n",
    "2. Decision region plots for GMM based classifiers for Dataset 3. Superpose the training data on the decision region plot. Superpose the plots of level curves on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Dataset-3/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Dataset-3/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m y_train \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Dataset-3/test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"./Dataset-3/test.csv\")\n",
    "X_train = data[['x1','x2']].values.astype('float')\n",
    "data_test = pd.read_csv(\"./Dataset-3/test.csv\")\n",
    "X_test = data_test[['x1','x2']].values.astype('float')\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# Predict class for a grid of values to plot decision regions\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def first_task(gmm_0,gmm_1):\n",
    "    \n",
    "    # Calculate log-likelihood for training data\n",
    "    log_likelihood_train_0 = gmm_0.score_samples(X_train)  # For class 0\n",
    "    log_likelihood_train_1 = gmm_1.score_samples(X_train)  # For class 1\n",
    "\n",
    "    # Assign class based on higher log-likelihood for training data\n",
    "    y_train_pred = np.where(log_likelihood_train_0 > log_likelihood_train_1, 0, 1)\n",
    "\n",
    "    # Calculate log-likelihood for test data\n",
    "    log_likelihood_test_0 = gmm_0.score_samples(X_test)  # For class 0\n",
    "    log_likelihood_test_1 = gmm_1.score_samples(X_test)  # For class 1\n",
    "\n",
    "    # Assign class based on higher log-likelihood for test data\n",
    "    y_test_pred = np.where(log_likelihood_test_0 > log_likelihood_test_1, 0, 1)\n",
    "\n",
    "    # Compute confusion matrices\n",
    "    conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    # Compute accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print accuracies\n",
    "    print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Plot confusion matrices using seaborn heatmap\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Training confusion matrix plot\n",
    "    sns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "    ax[0].set_title('Confusion Matrix - Training Data')\n",
    "    ax[0].set_xlabel('Predicted Labels')\n",
    "    ax[0].set_ylabel('True Labels')\n",
    "\n",
    "    # Test confusion matrix plot\n",
    "    sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
    "    ax[1].set_title('Confusion Matrix - Test Data')\n",
    "    ax[1].set_xlabel('Predicted Labels')\n",
    "    ax[1].set_ylabel('True Labels')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Full covariance matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Datasets 3: Confusion matrices and classification accuracies for the training data and the test data, and for each of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m gmm_full_0 \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m gmm_full_1 \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m gmm_full_0\u001b[38;5;241m.\u001b[39mfit(X_train[y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      8\u001b[0m gmm_full_1\u001b[38;5;241m.\u001b[39mfit(X_train[y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      9\u001b[0m first_task(gmm_full_0,gmm_full_1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Define GMM models with 8 components per class and full/diagonal covariance types\n",
    "gmm_full_0 = GaussianMixture(n_components=8, covariance_type='full', random_state=42)\n",
    "gmm_full_1 = GaussianMixture(n_components=8, covariance_type='full', random_state=42)\n",
    "gmm_full_0.fit(X_train[y_train == 0])\n",
    "gmm_full_1.fit(X_train[y_train == 1])\n",
    "first_task(gmm_full_0,gmm_full_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.stats import multivariate_normal\n",
    "def plot_level_curves(mean, cov, plt, color):\n",
    "    \"\"\"Plot level curves (contours) for the Gaussian distribution.\"\"\"\n",
    "    x, y = np.mgrid[x_min:x_max:.01, y_min:y_max:.01]\n",
    "    pos = np.dstack((x, y))\n",
    "    rv = multivariate_normal(mean, cov)\n",
    "    \n",
    "    # Limit the levels to reduce extra lines\n",
    "    levels = np.linspace(0.01, rv.pdf(mean), 7)  # 7 levels between min and max probability\n",
    "    plt.contour(x, y, rv.pdf(pos), levels=levels, colors=color, alpha=0.7)\n",
    "def second_task(gmm_0,gmm_1,msg):\n",
    "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Get log likelihoods for both classes\n",
    "    log_likelihood_0 = gmm_0.score_samples(grid)\n",
    "    log_likelihood_1 = gmm_1.score_samples(grid)\n",
    "\n",
    "    # Predict the class with higher log likelihood\n",
    "    Z = np.where(log_likelihood_0 > log_likelihood_1, 0, 1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision region\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "    plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.6)\n",
    "\n",
    "    # Superpose training data points\n",
    "    plt.scatter(X_train[y_train == 0][:, 0], X_train[y_train == 0][:, 1], color='red', label='Class 0')\n",
    "    plt.scatter(X_train[y_train == 1][:, 0], X_train[y_train == 1][:, 1], color='blue', label='Class 1')\n",
    "\n",
    "    # Plot level curves for the Gaussians (Class 0)\n",
    "    for i in range(gmm_0.n_components):\n",
    "        mean = gmm_0.means_[i]\n",
    "        cov = gmm_0.covariances_[i]\n",
    "        plot_level_curves(mean, cov, plt, color='red')\n",
    "\n",
    "    # Plot level curves for the Gaussians (Class 1)\n",
    "    for i in range(gmm_1.n_components):\n",
    "        mean = gmm_1.means_[i]\n",
    "        cov = gmm_1.covariances_[i]\n",
    "        plot_level_curves(mean, cov, plt, color='blue')\n",
    "\n",
    "    plt.title('Decision Region with Level Curves for GMM Classifier ' + msg)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Helper function to plot level curves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decision region plots for GMM based classifiers for Dataset 3. Superpose the training data on the decision region plot. Superpose the plots of level curves on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m second_task(gmm_full_0,gmm_full_1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith full covariance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36msecond_task\u001b[1;34m(gmm_0, gmm_1, msg)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msecond_task\u001b[39m(gmm_0,gmm_1,msg):\n\u001b[1;32m---> 13\u001b[0m     x_min, x_max \u001b[38;5;241m=\u001b[39m X_train[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X_train[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     y_min, y_max \u001b[38;5;241m=\u001b[39m X_train[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X_train[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m     xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m500\u001b[39m), np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m500\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "second_task(gmm_full_0,gmm_full_1,\"with full covariance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Diagonal covariance matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Datasets 3: Confusion matrices and classification accuracies for the training data and the \n",
    "test data, and for each of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m gmm_diag_0 \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m gmm_diag_1 \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m gmm_diag_0\u001b[38;5;241m.\u001b[39mfit(X_train[y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m gmm_diag_1\u001b[38;5;241m.\u001b[39mfit(X_train[y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      6\u001b[0m first_task(gmm_diag_0,gmm_diag_1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define GMM models with 8 components per class and diagonal covariance types\n",
    "gmm_diag_0 = GaussianMixture(n_components=8, covariance_type='diag', random_state=42)\n",
    "gmm_diag_1 = GaussianMixture(n_components=8, covariance_type='diag', random_state=42)\n",
    "gmm_diag_0.fit(X_train[y_train == 0])\n",
    "gmm_diag_1.fit(X_train[y_train == 1])\n",
    "first_task(gmm_diag_0,gmm_diag_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decision region plots for GMM based classifiers for Dataset 3. Superpose the training data on the decision region plot. Superpose the plots of level curves on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m second_task(gmm_diag_0,gmm_diag_1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith diagonal covariance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36msecond_task\u001b[1;34m(gmm_0, gmm_1, msg)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msecond_task\u001b[39m(gmm_0,gmm_1,msg):\n\u001b[1;32m---> 13\u001b[0m     x_min, x_max \u001b[38;5;241m=\u001b[39m X_train[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X_train[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     y_min, y_max \u001b[38;5;241m=\u001b[39m X_train[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, X_train[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m     xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(x_min, x_max, \u001b[38;5;241m500\u001b[39m), np\u001b[38;5;241m.\u001b[39mlinspace(y_min, y_max, \u001b[38;5;241m500\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "second_task(gmm_diag_0,gmm_diag_1,\"with diagonal covariance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
